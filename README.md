### Hi there ðŸ‘‹
## MACHINE LEARNING

### 1. Setting up the environment
We trained our models on tf-nightly-gpu but it should be okay if it's trained on official releases of tensorflow
First we should install tensorflow model for our object detection using git clone :

```git clone https://github.com/tensorflow/models.git```

We also need to install protobuf, use this link bellow to download it.
>https://github.com/protocolbuffers/protobuf/releases

After you've done downloading you should move the "protoc" named file in the zip and move it to models/research. The next thing is you now should be able to install the API using these steps bellow.

*** Python Package installation ***
```
cd models/research
Compile protos.
protoc object_detection/protos/*.proto --python_out=.
Install TensorFlow Object Detection API.
cp object_detection/packages/tf2/setup.py .
python -m pip install .
```
if you're using protobuf version 3.5 or higher you should use this command

```python use_protobuf.py <path to directory> <path to protoc file>```

to test the installation :

```
# Test the installation.
python object_detection/builders/model_builder_tf2_test.py
```
if it's working correctly it should be written like this
```
...
[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config
[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto
[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto
[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
[ RUN      ] ModelBuilderTF2Test.test_session
[  SKIPPED ] ModelBuilderTF2Test.test_session
[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture
[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture
[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
----------------------------------------------------------------------
Ran 20 tests in 91.767s

OK (skipped=1)
```

### Problem that we encountered and how to fix it :
- pycocotools error 
>install C++ Build Tools using this link https://visualstudio.microsoft.com/visual-cpp-b and restart PC 
- tf-object-detection not found
>change tf-models-official to tf-models-nightly in the setup.py

### 2. Data Preprocessing

We use this dataset from a paper pubslished on ICCV 2019 
the paper link :
>https://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Joint_Acne_Image_Grading_and_Counting_via_Label_Distribution_Learning_ICCV_2019_paper.pdf

the github link :
>https://github.com/xpwu95/ldl

the dataset link :
>https://drive.google.com/drive/folders/18yJcHXhzOv7H89t-Lda6phheAicLqMuZ

We still need to properly clean the data and split the data between train and validation, you can use a note called img_note.txt to know which picture should be deleted because of broken xml file (of course you can re-label the picture using labelimg but we don't have any expertise to properly labeling the image) 

### 3. Generating Training Data
After labeling the image we should convert those xml files to csv using the xml_to_csv.py then use this command

```python xml_to_csv.py```

Different than the xml_to_csv file we need to tweak a few thing in this code if you want to change the label

```
def class_text_to_int(row_label):
    if row_label == 'fore':
        return 1
    else:
        return None
```

you should replace the row_label parameter and if you want to add another label then use elif condition returning 2 and so on.


Then we need to convert the csv file to the tfrecord, use this command

```
python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record
```
```
python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record
```

### 4. Getting Ready for Training
We need a label map that maps an id to a name. We will put label_map.pbtxt in a folder called training, which is located in the object_detection directory. here's what the code is about

```
item {
    id: 1
    name: 'fore'
}
```

Lastly, we need to create a training configuration file. As a base model, we use ssd mobilenet v2 320x320 because we were having issue with other model because of limitaion in GPU. The Tensorflow OD API provides a lot of different models. For more information check out this link bellow and download the model you want to use.
>https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

Then extract the model to the 
>Tensorflow\models\research\object_detection\

After we extract the model we need to edit the config for the model can be found inside the configs/tf2 folder.

Copy the config file to the training directory. Then open it inside a text editor and make the following changes:

>Line 13: change the number of classes to number of objects you want to detect

>Line 141: change fine_tune_checkpoint to the path of the model.ckpt file:

>fine_tune_checkpoint: "<path>/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0"

>Line 143: Change fine_tune_checkpoint_type to detection

>Line 182: change input_path to the path of the train.records file:

>input_path: "<path>/train.record"

>Line 197: change input_path to the path of the test.records file:

>input_path: "<path>/test.record"

>Line 180 and 193: change label_map_path to the path of the label map:

>label_map_path: "<path>/label_map.pbtxt"

>Line 144 and 189: change batch_size to a number appropriate for your hardware, like 4, 8, or 16. In our case we only can fit 1.

### 5. Training the model
Execute this command below to train the model

```
python model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v2_320x320_coco17_tpu-8.config --model_dir=training --alsologtostderr
```

and use this command to export the model we trained

```
python exporter_main_v2.py \ --trained_checkpoint_dir training \ --output_directory inference_graph \ --pipeline_config_path training/ssd_mobilenet_v2_320x320_coco17_tpu-8.config
```

## CLOUD COMPUTING

### 1. Setting up the environment
Build a VM instance in Google Cloud Platform (for this case, we use Linux OS for the VM) and Setting up our VM with the environment. The environement just almost same with Machine Learning, We need to install Object Detection API to our VM using these steps bellow.
1. Next to the instance name, click SSH.
2. Enter the following command to switch to the root user:
```
sudo -i
```

*** Install the Object Detection API ***
1. Install the prerequisite packages.
```
apt-get update
apt-get install -y protobuf-compiler python3-pil python3-lxml python3-pip python3-dev git
pip3 install -U pip
python3 -m pip install Flask==1.1.1 WTForms==2.2.1 Flask_WTF==0.14.2 Werkzeug==0.16.0
```

2. Install the Object Detection API library.
```
cd /opt
```
And then we should install tensorflow model for our object detection using git clone :
```git clone https://github.com/tensorflow/models```
```
cd models/research
```
We also need to install protobuf, use this link bellow to download it.
>https://github.com/protocolbuffers/protobuf/releases

Then we should to follow this step below for the installation.

```
Compile protos.
protoc object_detection/protos/*.proto --python_out=.
Install TensorFlow Object Detection API.
cp object_detection/packages/tf2/setup.py .
python -m pip install .
```
if you're using protobuf version 3.5 or higher you should use this command

```python use_protobuf.py <path to directory> <path to protoc file>```

### 2. Deploy the ML Model and launch the demo web application
1. Install the application.
```
cd $HOME
mkdir acne_detection
cd acne_detection
git clone https://github.com/B21-CAP007/B21-CAP007/tree/main/Cloud_Computing
cp -a acne_detection /opt/
chmod u+x /opt/acne_detection/app.py
cp /opt/acne_detection/object-detection.service /etc/systemd/system/
```

2. Launch the application.
```
systemctl daemon-reload
systemctl enable object-detection
systemctl start object-detection
systemctl status object-detection
```

3. Launch the demo website
Using a web browser, access the static IP from the external IP Address our VM instance. and then just upload an image file with a JPEG, JPG, or PNG extension. The application shows the result of the object detection inference. Depending on the size of the image, it might take up to 30 seconds to upload the image. 

*** Your API ready to serve ***

### RESOURCES MATERIAL
- https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model
- https://www.youtube.com/watch?v=cvyDYdI2nEI&t=714s
- https://cloud.google.com/architecture/creating-object-detection-application-tensorflow
<!--
**B21-CAP007/B21-CAP007** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

